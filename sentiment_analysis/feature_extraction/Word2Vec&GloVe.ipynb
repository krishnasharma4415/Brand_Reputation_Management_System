{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Convert to Dask DataFrame for parallel processing\n",
    "dask_df = dd.from_pandas(df, npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize and preprocess data (using Dask for parallel tokenization)\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Parallel tokenization\n",
    "with ProgressBar():\n",
    "    tokenized_reviews = dask_df['cleaned_review'].map(tokenize).compute()\n",
    "\n",
    "# Initialize and train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=2, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load GloVe embeddings (using Dask for parallel loading)\n",
    "def load_glove_embeddings(glove_file_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_file_path, 'r') as file:\n",
    "        for line in tqdm(file):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(\"glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model):\n",
    "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Apply sentence embeddings in parallel for Word2Vec\n",
    "with ProgressBar():\n",
    "    X_word2vec = dask_df['cleaned_review'].map(lambda x: get_sentence_embedding(x.split(), w2v_model)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_glove_embedding(sentence, embeddings):\n",
    "    vectors = [embeddings[word] for word in sentence if word in embeddings]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(100)  # 100 is the dimension of GloVe vectors\n",
    "\n",
    "with ProgressBar():\n",
    "    X_glove = dask_df['cleaned_review'].map(lambda x: get_sentence_glove_embedding(x.split(), glove_embeddings)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Convert to cuDF for GPU usage\n",
    "X_word2vec = cudf.DataFrame.from_pandas(pd.DataFrame(X_word2vec))\n",
    "X_glove = cudf.DataFrame.from_pandas(pd.DataFrame(X_glove))\n",
    "y_cudf = cudf.Series(y)\n",
    "\n",
    "# Split the data\n",
    "X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(X_word2vec, y_cudf, test_size=0.2, random_state=42)\n",
    "X_train_glove, X_test_glove, _, _ = train_test_split(X_glove, y_cudf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation with Word2Vec embeddings\n",
    "model_w2v = MultinomialNB()\n",
    "model_w2v.fit(X_train_w2v, y_train)\n",
    "y_pred_w2v = model_w2v.predict(X_test_w2v)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Word2Vec Classification Report:\")\n",
    "print(classification_report(y_test.to_array(), y_pred_w2v.to_array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glove = MultinomialNB()\n",
    "model_glove.fit(X_train_glove, y_train)\n",
    "y_pred_glove = model_glove.predict(X_test_glove)\n",
    "\n",
    "# Evaluate\n",
    "print(\"GloVe Classification Report:\")\n",
    "print(classification_report(y_test.to_array(), y_pred_glove.to_array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "performance = pd.DataFrame({\n",
    "    \"Model\": [\"Word2Vec\", \"GloVe\"],\n",
    "    \"Accuracy\": [accuracy_score(y_test.to_array(), y_pred_w2v.to_array()), accuracy_score(y_test.to_array(), y_pred_glove.to_array())]\n",
    "})\n",
    "\n",
    "sns.barplot(x=\"Model\", y=\"Accuracy\", data=performance)\n",
    "plt.title(\"Word2Vec vs GloVe Model Performance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
